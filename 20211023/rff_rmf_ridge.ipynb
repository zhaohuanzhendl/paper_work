{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454275ba",
   "metadata": {
    "lines_to_end_of_cell_marker": 2,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "#from   rffridge import RFFRidgeRegression\n",
    "from   sklearn.gaussian_process.kernels import RBF\n",
    "from   sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from   sklearn.exceptions import NotFittedError\n",
    "from   sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.utils import check_random_state, check_array\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from scipy.special import factorial, binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ab2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RFFRidgeRegression:\n",
    "\n",
    "    def __init__(self, rff_dim=1, alpha=1.0, sigma=1.0):\n",
    "        \"\"\"Kernel ridge regression using random Fourier features.\n",
    "        rff_dim : Dimension of random feature.\n",
    "        alpha :   Regularization strength. Should be a positive float.\n",
    "        \"\"\"\n",
    "        self.fitted  = False\n",
    "        self.rff_dim = rff_dim\n",
    "        self.sigma   = sigma\n",
    "        self.lm      = Ridge(alpha=alpha)\n",
    "        self.b_      = None\n",
    "        self.W_      = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit model with training data X and target y.\n",
    "        \"\"\"\n",
    "        Z, W, b = self._get_rffs(X, return_vars=True)\n",
    "        self.lm.fit(Z.T, y)\n",
    "        self.b_ = b\n",
    "        self.W_ = W\n",
    "        self.fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using fitted model and testing data X.\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            msg = \"Call 'fit' with appropriate arguments first.\"\n",
    "            raise NotFittedError(msg)\n",
    "        Z = self._get_rffs(X, return_vars=False)\n",
    "        print(\"Z.shape:\", Z.shape)\n",
    "        return self.lm.predict(Z.T)\n",
    "\n",
    "    def _get_rffs(self, X, return_vars):\n",
    "        \"\"\"Return random Fourier features based on data X, as well as random\n",
    "        variables W and b.\n",
    "        \"\"\"\n",
    "        N, D = X.shape\n",
    "        if self.W_ is not None:\n",
    "            W, b = self.W_, self.b_\n",
    "        else:\n",
    "            W = np.random.normal(loc=0, scale=1, size=(self.rff_dim, D))\n",
    "            b = np.random.uniform(0, 2*np.pi, size=self.rff_dim)\n",
    "\n",
    "        B    = np.repeat(b[:, np.newaxis], N, axis=1)\n",
    "        norm = 1./ np.sqrt(self.rff_dim)\n",
    "        Z    = norm * np.sqrt(2) * np.cos(self.sigma * W @ X.T + B)\n",
    "\n",
    "        if return_vars:\n",
    "            return Z, W, b\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49212c2d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class RandomMaclaurin():\n",
    "\n",
    "    def __init__(self, D=50, p=2, kernel='exp',\n",
    "                 gamma=1.0, coefs=None, \n",
    "                 max_expansion=50,\n",
    "                 random_state=123, \n",
    "                 alpha=1.0):\n",
    "\n",
    "        self.D = D\n",
    "        self.p = p\n",
    "        self.gamma = gamma\n",
    "        # coefs of Maclaurin series.\n",
    "        self.coefs = coefs\n",
    "        self.kernel = kernel\n",
    "        self.max_expansion = max_expansion\n",
    "        self.p_choice = None\n",
    "        self.random_state = random_state\n",
    "        self.fitted = False\n",
    "        self.lm = Ridge(alpha=alpha)\n",
    "\n",
    "    def _set_coefs(self, gamma):\n",
    "        if self.coefs is None:\n",
    "            if self.kernel == 'exp':\n",
    "                self.coefs = gamma ** np.arange(self.max_expansion)\n",
    "                self.coefs /= factorial(range(self.max_expansion))\n",
    "            else:\n",
    "                raise ValueError(\"When using the user-specific kernel \"\n",
    "                                 \"function, coefs must be given explicitly.\")\n",
    "\n",
    "    def _sample_orders(self, random_state):\n",
    "        coefs = np.array(self.coefs)\n",
    "\n",
    "        if self.p_choice is None:\n",
    "            p_choice = (1/self.p) ** (np.arange(len(coefs)) + 1)\n",
    "            if np.sum(coefs == 0.) != 0:\n",
    "                p_choice[coefs == 0] = 0\n",
    "            p_choice /= np.sum(p_choice)\n",
    "            self.p_choice = p_choice\n",
    "\n",
    "        self.orders_ = random_state.choice(len(self.p_choice),\n",
    "                                           self.D,\n",
    "                                           p=self.p_choice).astype(np.int32) + 1\n",
    "\n",
    "    def _rademacher(self, random_state, size):\n",
    "        return random_state.randint(2, size=size, dtype=np.int32)*2-1\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        random_state = check_random_state(self.random_state)\n",
    "        X = check_array(X, accept_sparse=False)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        if self.gamma == 'auto':\n",
    "            gamma = 1.0 / X.shape[1]\n",
    "        else:\n",
    "            gamma = self.gamma\n",
    "\n",
    "        self._set_coefs(gamma)\n",
    "        self._sample_orders(random_state)\n",
    "        #distribution = self.distribution.lower()\n",
    "        size = (n_features, np.sum(self.orders_))\n",
    "        self.random_weights_ = self._rademacher(random_state,size).astype(np.float64)\n",
    "        self.fitted = True\n",
    "        \n",
    "        Z = self.transform(X)\n",
    "        self.lm.fit(Z.T, y)\n",
    "        return self\n",
    "\n",
    "\n",
    "    def transform_implement(self, X):\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        #Z = np.zeros((n_samples, self.D))\n",
    "        Z = np.ones((n_samples, self.D))\n",
    "        print(self.orders_)\n",
    "        #print(self.random_weights_)\n",
    "        #print(self.random_weights_.shape)\n",
    "        for row in range(n_samples):\n",
    "            sample = X[row]\n",
    "            weight_offset = 0\n",
    "            for i in range(self.D):\n",
    "                #weight_offset = 0\n",
    "                N = self.orders_[i]\n",
    "                a_N = self.coefs[N]\n",
    "                for j in range(1, N+1):\n",
    "                    #print(\"j:\", j)\n",
    "                    #print(\"N:\", N)\n",
    "                    #print(\"weight_offset:\", weight_offset)\n",
    "                    Z[row][i] *= np.sum(self.random_weights_[:, weight_offset] * sample)\n",
    "                    weight_offset += 1\n",
    "                Z[row][i] *= np.sqrt(a_N * (self.p**(N+1)))\n",
    "\n",
    "            #print(\"weight_offset:\", weight_offset)\n",
    "        print(\"rmf Z.T.shape:\", Z.T.shape)\n",
    "        #print(\"Z:\", Z)\n",
    "        return Z.T\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Apply the approximate feature map to X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "            New data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_new : array-like, shape (n_samples, D)\n",
    "        \"\"\"\n",
    "        #check_is_fitted(self, \"random_weights_\")\n",
    "        X = check_array(X, accept_sparse=True)\n",
    "        n_samples, n_features = X.shape\n",
    "        X_new = self.transform_implement(X)\n",
    "\n",
    "        return X_new\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using fitted model and testing data X.\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            msg = \"Call 'fit' with appropriate arguments first.\"\n",
    "            raise NotFittedError(msg)\n",
    "        Z = self.transform(X)\n",
    "        return self.lm.predict(Z.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N     = 100\n",
    "X     = np.linspace(-10, 10, N)[:, None]\n",
    "mean  = np.zeros(N)\n",
    "print(X.shape, X.reshape(N, -1).shape)\n",
    "cov   = RBF()(X.reshape(N, -1))\n",
    "print(cov.shape)\n",
    "#print(X.reshape(N, -1))\n",
    "y     = np.random.multivariate_normal(mean, cov)\n",
    "noise = np.random.normal(0, 0.5, N)\n",
    "y    += noise\n",
    "# Finer resolution for smoother curve visualization.\n",
    "X_test = np.linspace(-10, 10, N*2)[:, None]\n",
    "#print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18000b9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Set up figure and plot data.\n",
    "fig, axes = plt.subplots(3, 1)\n",
    "fig.set_size_inches(10, 10)\n",
    "ax1, ax2, ax3  = axes\n",
    "cmap      = plt.cm.get_cmap('Blues')\n",
    "#print(X,y)\n",
    "ax1.scatter(X, y, s=30, c=[cmap(0.3)])\n",
    "ax2.scatter(X, y, s=30, c=[cmap(0.3)])\n",
    "ax3.scatter(X, y, s=30, c=[cmap(0.3)])\n",
    "\n",
    "# Fit kernel ridege regression using an RBF kernel.\n",
    "clf_1    = KernelRidge(kernel=RBF())\n",
    "clf_1    = clf.fit(X, y)\n",
    "y_pred = clf_1.predict(X_test)\n",
    "ax1.plot(X_test, y_pred, c=cmap(0.9))\n",
    "\n",
    "# Fit kernel ridge regression using random Fourier features.\n",
    "rff_dim = 20\n",
    "clf_2 = RFFRidgeRegression(rff_dim=rff_dim)\n",
    "clf_2.fit(X, y)\n",
    "y_pred  = clf_2.predict(X_test)\n",
    "ax2.plot(X_test, y_pred, c=cmap(0.9))\n",
    "\n",
    "D=100\n",
    "clf_3 = RandomMaclaurin(D=D)\n",
    "clf_3.fit(X, y)\n",
    "y_pred  = clf_3.predict(X_test)\n",
    "ax3.plot(X_test, y_pred, c=cmap(0.9))\n",
    "\n",
    "# Labels, etc.\n",
    "ax1.margins(0, 0.1)\n",
    "ax1.set_title('RBF kernel regression')\n",
    "ax1.set_ylabel(r'$y$', fontsize=14)\n",
    "ax1.set_xticks([])\n",
    "\n",
    "ax2.margins(0, 0.1)\n",
    "ax2.set_title(rf'RFF ridge regression, $R = {rff_dim}$')\n",
    "ax2.set_ylabel(r'$y$', fontsize=14)\n",
    "ax2.set_xlabel(r'$x$', fontsize=14)\n",
    "ax2.set_xticks(np.arange(-10, 10.1, 1))\n",
    "\n",
    "ax3.margins(0, 0.1)\n",
    "ax3.set_title(rf'RMF regression, $D = {50}$')\n",
    "ax3.set_ylabel(r'$y$', fontsize=14)\n",
    "ax3.set_xlabel(r'$x$', fontsize=14)\n",
    "ax3.set_xticks(np.arange(-10, 10.1, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4e5cf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
